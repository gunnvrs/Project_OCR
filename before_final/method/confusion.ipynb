{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทดลองทำการ Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# สมมุติว่ามี Ground Truth และ Predicted Text\n",
    "ground_truth = \"กรุงเทพมหานคร\"\n",
    "predicted_text = \"กรุงเทหมาหา\"\n",
    "\n",
    "# สร้าง list ของตัวอักษรจาก Ground Truth และ Predicted Text\n",
    "ground_truth_chars = list(ground_truth)\n",
    "predicted_chars = list(predicted_text)\n",
    "\n",
    "# เพิ่มความยาวของ list ให้ตรงกัน\n",
    "max_len = max(len(ground_truth_chars), len(predicted_chars))\n",
    "ground_truth_chars = ground_truth_chars + [''] * (max_len - len(ground_truth_chars))\n",
    "predicted_chars = predicted_chars + [''] * (max_len - len(predicted_chars))\n",
    "\n",
    "# สร้าง confusion matrix\n",
    "cm = confusion_matrix(ground_truth_chars, predicted_chars, labels=np.unique(ground_truth_chars + predicted_chars))\n",
    "\n",
    "# แสดง confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# แสดงผล classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(ground_truth_chars, predicted_chars))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ทดลอง 29 Aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "พบว่ามีช่องว่าง ผลเลยเพี้ยน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive (TP): 2\n",
      "False Positive (FP): 1705\n",
      "False Negative (FN): 33\n",
      "Accuracy: 0.00\n",
      "Precision: 0.00\n",
      "Recall: 0.06\n",
      "Text extracted, cleaned, and saved to /Users/gunnviryasiri/Desktop/ocr/results/ocr_output_20240829_200631.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "# ตั้งค่าเส้นทางไปยัง Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/bin/tesseract'\n",
    "\n",
    "# Path to the image file\n",
    "image_path = '/Users/gunnviryasiri/Desktop/ocr/testfile/file1.jpg'\n",
    "\n",
    "# Path to the reference file\n",
    "reference_text_file = '/Users/gunnviryasiri/Desktop/ocr/results/FORTEST.txt'\n",
    "\n",
    "# สร้างชื่อไฟล์จากวันที่และเวลา\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_text_file = f'/Users/gunnviryasiri/Desktop/ocr/results/ocr_output_{current_time}.txt'\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = image.convert('L')\n",
    "\n",
    "# Perform OCR on the image using Thai and English languages\n",
    "custom_config = r'--tessdata-dir \"/Users/gunnviryasiri/pythainlp-data/tessdata\" --oem 3 --psm 6'\n",
    "text = pytesseract.image_to_string(gray, config=custom_config, lang='tha+eng')\n",
    "\n",
    "# Save the extracted text to a file\n",
    "with open(output_text_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "\n",
    "# อ่านข้อความที่ถูกต้องจากไฟล์ reference\n",
    "with open(reference_text_file, 'r', encoding='utf-8') as f:\n",
    "    correct_text_lines = f.readlines()\n",
    "\n",
    "# อ่านข้อความที่ OCR มาได้\n",
    "with open(output_text_file, 'r', encoding='utf-8') as f:\n",
    "    ocr_text_lines = f.readlines()\n",
    "\n",
    "# เปรียบเทียบข้อความทีละบรรทัด\n",
    "tp = fp = fn = 0\n",
    "\n",
    "for correct_line, ocr_line in zip(correct_text_lines, ocr_text_lines):\n",
    "    correct_words = correct_line.strip().split()\n",
    "    ocr_words = ocr_line.strip().split()\n",
    "\n",
    "    # นับจำนวนคำที่ match กัน\n",
    "    for word in correct_words:\n",
    "        if word in ocr_words:\n",
    "            tp += 1  # True Positive\n",
    "            ocr_words.remove(word)  # เอาคำที่ match ออกเพื่อลดการนับซ้ำ\n",
    "        else:\n",
    "            fn += 1  # False Negative: คำที่ขาดหายไป\n",
    "\n",
    "    # คำที่เหลือใน ocr_words คือตัว False Positive: คำที่เกินมา\n",
    "    fp += len(ocr_words)\n",
    "\n",
    "# แสดงผลลัพธ์ Confusion Matrix\n",
    "print(f\"True Positive (TP): {tp}\")\n",
    "print(f\"False Positive (FP): {fp}\")\n",
    "print(f\"False Negative (FN): {fn}\")\n",
    "\n",
    "accuracy = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "print(f'Text extracted, cleaned, and saved to {output_text_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ที่กพท๐๕/#๑๕ต๒สํานักงานการบินพลเรือนแห่งประเทศไทย\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ฟังก์ชันสำหรับลบช่องว่างที่ไม่จำเป็น\n",
    "def remove_unnecessary_spaces(text):\n",
    "    # ลบช่องว่างระหว่างตัวอักษรไทยที่ไม่ควรมีช่องว่าง\n",
    "    text = re.sub(r'\\s+', '', text)\n",
    "    # ลบช่องว่างระหว่างอักษรไทยที่มีสระหรือตัวสะกด\n",
    "    text = re.sub(r'([ก-ฮ])\\s+([่-๋็-์])', r'\\1\\2', text)\n",
    "    # ลบช่องว่างระหว่างตัวเลข\n",
    "    text = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', text)\n",
    "    return text\n",
    "\n",
    "# ตัวอย่างการใช้งาน\n",
    "ocr_text = \"ท ี ่ ก พ ท ๐ ๕ /# ๑ ๕ ต ๒ ส ํ า น ั ก ง า น ก า ร บ ิ น พ ล เร ื อ น แห ่ ง ป ร ะ เท ศ ไท ย\"\n",
    "cleaned_text = remove_unnecessary_spaces(ocr_text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "แก้ไม่ได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive (TP): 1\n",
      "False Positive (FP): 154\n",
      "False Negative (FN): 0\n",
      "Accuracy: 0.01\n",
      "Precision: 0.01\n",
      "Recall: 1.00\n",
      "Text extracted, cleaned, and saved to /Users/gunnviryasiri/Desktop/ocr/results/ocr_output_20240829_200437.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# ตั้งค่าเส้นทางไปยัง Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/bin/tesseract'\n",
    "\n",
    "# Path to the image file\n",
    "image_path = '/Users/gunnviryasiri/Desktop/ocr/testfile/file1.jpg'\n",
    "\n",
    "# Path to the reference file\n",
    "reference_text_file = '/Users/gunnviryasiri/Desktop/ocr/results/FORTEST.txt'\n",
    "\n",
    "# สร้างชื่อไฟล์จากวันที่และเวลา\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_text_file = f'/Users/gunnviryasiri/Desktop/ocr/results/ocr_output_{current_time}.txt'\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = image.convert('L')\n",
    "\n",
    "# Perform OCR on the image using Thai and English languages\n",
    "custom_config = r'--tessdata-dir \"/Users/gunnviryasiri/pythainlp-data/tessdata\" --oem 3 --psm 6'\n",
    "text = pytesseract.image_to_string(gray, config=custom_config, lang='tha+eng')\n",
    "\n",
    "# ฟังก์ชันสำหรับการประมวลผลข้อความหลังการ OCR\n",
    "def post_process(text):\n",
    "    # รวมคำที่มีช่องว่างเกิน\n",
    "    text = re.sub(r'([ก-ฮa-zA-Z0-9])\\s+([ก-ฮa-zA-Z0-9])', r'\\1 \\2', text)\n",
    "    \n",
    "    # ลบช่องว่างที่เกินที่ท้ายบรรทัด\n",
    "    text = re.sub(r'\\s+$', '', text)\n",
    "    \n",
    "    # แทนที่ช่องว่างที่เกินทั้งหมดในเอกสารด้วยช่องว่างเดียว\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Post-process the OCR result\n",
    "text = post_process(text)\n",
    "\n",
    "# Save the extracted text to a file\n",
    "with open(output_text_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "\n",
    "# อ่านข้อความที่ถูกต้องจากไฟล์ reference\n",
    "with open(reference_text_file, 'r', encoding='utf-8') as f:\n",
    "    correct_text_lines = f.readlines()\n",
    "\n",
    "# อ่านข้อความที่ OCR มาได้\n",
    "with open(output_text_file, 'r', encoding='utf-8') as f:\n",
    "    ocr_text_lines = f.readlines()\n",
    "\n",
    "# เปรียบเทียบข้อความทีละบรรทัด\n",
    "tp = fp = fn = 0\n",
    "\n",
    "for correct_line, ocr_line in zip(correct_text_lines, ocr_text_lines):\n",
    "    correct_words = set(correct_line.strip().split())\n",
    "    ocr_words = set(ocr_line.strip().split())\n",
    "\n",
    "    # คำนวณ True Positive, False Positive และ False Negative\n",
    "    tp += len(correct_words.intersection(ocr_words))\n",
    "    fp += len(ocr_words - correct_words)\n",
    "    fn += len(correct_words - ocr_words)\n",
    "\n",
    "# แสดงผลลัพธ์ Confusion Matrix\n",
    "print(f\"True Positive (TP): {tp}\")\n",
    "print(f\"False Positive (FP): {fp}\")\n",
    "print(f\"False Negative (FN): {fn}\")\n",
    "\n",
    "accuracy = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "print(f'Text extracted, cleaned, and saved to {output_text_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 sep\n",
    "- ทำการเตรียม dataset น้อยๆ เพื่อเตรียม bipartite\n",
    "\n",
    "- ข้อมูล แบบ shift หน้า, หลัง , เว้น2ช่อง เว้นช่องเดียว \n",
    "\n",
    "- ถ้าหากทำเสร็จก็ไปข้ามเรื่อง pre,post processings ได้แล้ว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from pythainlp.corpus import thai_words\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import difflib\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "nltk.download('words', quiet=True)\n",
    "\n",
    "# กำหนด path ของ Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/bin/tesseract'\n",
    "\n",
    "# ฟังก์ชันคำนวณ Similarity ระหว่างสองคำ\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# ฟังก์ชันหาการจับคู่ที่ดีที่สุดแบบ Global\n",
    "def find_best_matching(reference, ocr):\n",
    "    ref_chars = list(reference)\n",
    "    ocr_chars = list(ocr)\n",
    "    \n",
    "    best_matching = []\n",
    "    for i, ref_char in enumerate(ref_chars):\n",
    "        best_match = None\n",
    "        best_sim = 0\n",
    "        for j, ocr_char in enumerate(ocr_chars):\n",
    "            sim = similarity(ref_char, ocr_char)\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_match = (i, j)\n",
    "        \n",
    "        if best_match:\n",
    "            best_matching.append(best_match)\n",
    "    \n",
    "    return best_matching\n",
    "\n",
    "# ฟังก์ชันสำหรับการ Post-Processing\n",
    "def post_process_matching(reference, ocr, matching, accuracy_threshold=0.7):\n",
    "    matched_chars = ['_'] * len(reference)\n",
    "    correct_chars = 0\n",
    "    error_details = []\n",
    "    \n",
    "    for ref_index, ocr_index in matching:\n",
    "        if ref_index < len(reference) and ocr_index < len(ocr):\n",
    "            if reference[ref_index] == ocr[ocr_index]:\n",
    "                matched_chars[ref_index] = ocr[ocr_index]\n",
    "                correct_chars += 1\n",
    "            else:\n",
    "                error_details.append(f\"Position {ref_index + 1}: Expected '{reference[ref_index]}', Got '{ocr[ocr_index]}'\")\n",
    "    \n",
    "    # Handle missing and extra characters\n",
    "    if len(ocr) < len(reference):\n",
    "        for i in range(len(ocr), len(reference)):\n",
    "            error_details.append(f\"Position {i + 1}: Expected '{reference[i]}', Got ' ' (missing)\")\n",
    "    elif len(ocr) > len(reference):\n",
    "        for i in range(len(reference), len(ocr)):\n",
    "            error_details.append(f\"Position {i + 1}: Expected ' ' (extra), Got '{ocr[i]}'\")\n",
    "    \n",
    "    accuracy = correct_chars / len(reference) if len(reference) > 0 else 0\n",
    "    \n",
    "    if accuracy >= accuracy_threshold:\n",
    "        return \"\".join(matched_chars), accuracy, error_details\n",
    "    else:\n",
    "        return \"\".join(matched_chars), accuracy, error_details\n",
    "\n",
    "# เริ่มกระบวนการ OCR\n",
    "image_path = '/Users/gunnviryasiri/Desktop/ocr/testfile/file1.jpg'\n",
    "reference_text_file = '/Users/gunnviryasiri/Desktop/ocr/results/FORTEST.txt'\n",
    "\n",
    "# โหลดและประมวลผลรูปภาพ\n",
    "image = Image.open(image_path)\n",
    "gray_image = image.convert('L')\n",
    "\n",
    "custom_config = r'--tessdata-dir \"/Users/gunnviryasiri/pythainlp-data/tessdata\" --oem 3 --psm 6'\n",
    "\n",
    "ocr_text = pytesseract.image_to_string(gray_image, config=custom_config, lang='tha+eng')\n",
    "\n",
    "# ลบเฉพาะบรรทัดว่าง\n",
    "processed_ocr_text = \"\\n\".join([line for line in ocr_text.splitlines() if line.strip()])\n",
    "\n",
    "# บันทึกผลลัพธ์ OCR ลงไฟล์\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_text_file = f'/Users/gunnviryasiri/Desktop/ocr/results/ocr_output_{current_time}.txt'\n",
    "with open(output_text_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(processed_ocr_text)\n",
    "\n",
    "# โหลดข้อมูลต้นฉบับ\n",
    "with open(reference_text_file, 'r', encoding='utf-8') as f:\n",
    "    reference_text = f.read().replace(\"\\n\", \"\")\n",
    "\n",
    "# ลบ newlines ในข้อความ OCR ที่ประมวลผลแล้ว\n",
    "processed_ocr_text = processed_ocr_text.replace(\"\\n\", \"\")\n",
    "\n",
    "# หาการจับคู่ที่ดีที่สุดแบบ Global\n",
    "best_matching = find_best_matching(reference_text, processed_ocr_text)\n",
    "\n",
    "# ทำการ Post-Processing โดยใช้ Global Match\n",
    "processed_text, final_accuracy, error_details = post_process_matching(reference_text, processed_ocr_text, best_matching)\n",
    "\n",
    "# คำนวณตัวชี้วัดผลลัพธ์สุดท้าย\n",
    "total_chars = len(reference_text)\n",
    "correct_chars = processed_text.count('_')  # เปลี่ยนตรงนี้เป็นการนับจำนวน underscore\n",
    "incorrect_chars = total_chars - correct_chars\n",
    "\n",
    "precision = (correct_chars / (correct_chars + incorrect_chars)) * 100 if (correct_chars + incorrect_chars) > 0 else 0\n",
    "recall = (correct_chars / total_chars) * 100 if total_chars > 0 else 0\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(f\"Total Characters in Reference Text: {total_chars}\")\n",
    "print(f\"Correct Characters: {correct_chars}\")\n",
    "print(f\"Incorrect Characters: {incorrect_chars}\\n\")\n",
    "\n",
    "print(\"=== Metrics ===\")\n",
    "print(f\"Final Accuracy: {final_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\\n\")\n",
    "\n",
    "print(\"=== Character Error Details ===\")\n",
    "for detail in error_details:\n",
    "    print(detail)\n",
    "\n",
    "print(\"=== Processed Text ===\")\n",
    "print(processed_text)\n",
    "\n",
    "print(f\"\\nText extracted, cleaned, and saved to {output_text_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv3110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
